{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596901352572",
   "display_name": "Python 3.8.4 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conv block\n",
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size = 3, bn = True):\n",
    "        super(Conv_Block, self).__init__()\n",
    "        #TODO: Add negation and scale/shift part of C.ReLu part.\n",
    "        layers = []\n",
    "        conv2d = nn.Conv2d(in_channel, out_channel, kernel_size)\n",
    "        #if batch normalization is needed\n",
    "        if bn:\n",
    "            layers +=[conv2d, nn.BatchNorm2d(out_channel)]\n",
    "        else:\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "model_urls = {\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#VGG16 block\n",
    "cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, in_channels, cfg, batch_norm = True, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self.make_layers(in_channels, cfg, batch_norm)\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "\n",
    "    def make_layers(self, in_channels, cfg, batch_norm):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = []\n",
    "        for m in self.features:\n",
    "            x = m(x)\n",
    "            if isinstance(m, nn.MaxPool2d):\n",
    "                out.append(x)\n",
    "\n",
    "        return out[1:] #only last 4 layers are used \n",
    "\n",
    "\n",
    "def vgg16(in_channels, pretrained, **kwargs):\n",
    "    '''\n",
    "    Function to load vgg16 features model\n",
    "    '''\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    \n",
    "    model = VGG(in_channels, cfg, **kwargs)\n",
    "\n",
    "    #download model from url\n",
    "    if pretrained:\n",
    "        if kwargs['batch_norm']:\n",
    "            url = model_urls['vgg16_bn']\n",
    "        else:\n",
    "            url = model_urls['vgg16']\n",
    "\n",
    "        state_dict = load_state_dict_from_url(url, progress = True)\n",
    "        state_dict = remove_classifier_keys(state_dict)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def remove_classifier_keys(state_dict):\n",
    "\n",
    "    new_state_dict = state_dict.copy()\n",
    "    for key in state_dict.keys():\n",
    "        if key.find(\"classifier\") != -1:\n",
    "            try:\n",
    "                new_state_dict.pop(key)\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = vgg16(3, True, batch_norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature merging branch\n",
    "class Merger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Merger, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1024, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(384, 64, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(192, 32, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        \n",
    "        #init weight by He init\n",
    "        self._initialize_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = F.interpolate(x[3], scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        y = torch.cat([y, x[2]], 1)\n",
    "        y = self.relu1(self.bn1(self.conv1(y)))\n",
    "        y = self.relu2(self.bn2(self.conv2(y)))\n",
    "        \n",
    "        y = F.interpolate(y, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        y = torch.cat((y, x[1]), 1)\n",
    "        y = self.relu3(self.bn3(self.conv3(y)))\n",
    "        y = self.relu4(self.bn4(self.conv4(y)))\n",
    "        \n",
    "        y = F.interpolate(y, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        y = torch.cat((y, x[0]), 1)\n",
    "        y = self.relu5(self.bn5(self.conv5(y)))\n",
    "        y = self.relu6(self.bn6(self.conv6(y)))\n",
    "        \n",
    "        y = self.relu7(self.bn7(self.conv7(y)))\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(nn.Module):\n",
    "    def __init__(self, scope=512):\n",
    "        super(Output, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(32, 1, 1)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.conv2 = nn.Conv2d(32, 4, 1)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.conv3 = nn.Conv2d(32, 1, 1)\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "        self.scope = scope\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        score = self.sigmoid1(self.conv1(x))\n",
    "        loc   = self.sigmoid2(self.conv2(x)) * self.scope\n",
    "        angle = (self.sigmoid3(self.conv3(x)) - 0.5) * math.pi\n",
    "        return score, loc, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EAST(nn.Module):\n",
    "    def __init__(self, in_channels ,pretrained = True, **kwargs):\n",
    "        super(EAST, self).__init__()\n",
    "\n",
    "        self.feature_extractor = vgg16(in_channels, pretrained, **kwargs)\n",
    "        self.merger = Merger()\n",
    "        self.output = Output()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.merger(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 128, 128, 128])\ntorch.Size([1, 256, 64, 64])\ntorch.Size([1, 512, 32, 32])\ntorch.Size([1, 512, 16, 16])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None, None, None]"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "test_input = torch.randn(1, 3, 512, 512)\n",
    "out = model(test_input)\n",
    "[print(o.shape) for o in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "east = EAST(3, batch_norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = east(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 1, 128, 128])\ntorch.Size([1, 4, 128, 128])\ntorch.Size([1, 1, 128, 128])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None, None]"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "[print(o.shape) for o in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 1, 128, 128])"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "p[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.cat([out[2], x], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 1024, 32, 32])"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}